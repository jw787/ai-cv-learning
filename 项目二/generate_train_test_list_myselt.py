from __future__ import print_function
import numpy as np
from PIL import Image
import os
import matplotlib.pyplot as plt
import torch
from torchvision import transforms, utils
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.utils.data.sampler import SubsetRandomSampler
from sklearn.model_selection import train_test_split

folder_list = ["./data/I/", "./data/II/"]

train_name = "train.txt"
test_name = "test.txt"
data1_root_file = "./data/I/label.txt"
data2_root_file = "./data/II/label.txt"


# # ä¸ºäº†è·å–ç”Ÿæˆbounding boxçš„åæ ‡
# def gen_bbox(label_txt):
#     with open(label_txt, "r") as f:
#         lines = f.readlines()
#         # print(lines)
#     # å› ä¸ºreadlinesï¼ˆï¼‰å¯ä»¥æŠŠæ¯ä¸€è¡Œå½“åšä¸€ä¸ªå…ƒç´ å‚¨å­˜èµ·æ¥ï¼Œæ‰€ä»¥for line in lineså°±ä¼šéå†æ¯ä¸€è¡Œ
#     bbox_list = []
#     for line in lines:
#         line = line.strip()  # å› ä¸ºreadlineså®ƒåŒ…æ‹¬æ¢è¡Œç¬¦ï¼Œæ‰€ä»¥strip()æ˜¯å°†æ¢è¡Œç¬¦ç»™å»äº†
#         # print(line)
#         components = line.split()
#         # print(components)
#         bbox = [components[1], components[2], components[3], components[4]]
#         # print(bbox)
#         bbox_list.append(bbox)
# [['229.0', '38.0', '289.0', '99.0'], ['4.0', '54.0', '109.0', '158.0'], ['44.0', '9.0', '153.0', '118.0'], ['218.0', '82.0', '328.0', '192.0'],.....] listå½¢å¼
# print(bbox_list)
# print(len(bbox_list))  # 1953
# return bbox_list

# def gen_bbox(label_txt):
#     data = pd.read_csv(data1_root_file, delimiter=" ")
#     print(data)
#     x = data.iloc[0, :]
#     print(x)
#
#     return x

def get_bbox(label_txt):
    # ä¸ç”¨æƒ³ä¸€æ¬¡æ€§å°†ä¸¤ç§æ•°æ®ç±»å‹éƒ½ä¸€ä¸‹å­èƒ½åˆ†ç¦»å¼€æ¥ï¼Œåªè¦å°†å®ƒä»¬ç»Ÿä¸€æˆå­—ç¬¦ä¸²çš„å½¢å¼åˆ†å‰²å¼€æ¥ï¼Œç„¶åæƒ³è¦æ•°å­—æ˜¯åœ¨å°†å…¶è½¬åŒ–è¿‡æ¥å³å¯
    data = np.loadtxt(label_txt, dtype=str)
    # print(data)
    bbox = data[:, 1:5].astype("float")
    # print(bbox)
    return bbox


# gen_bbox(data1_root_file)


# def gen_landmark(label_txt):
#     with open(label_txt, "r") as f:
#         lines = f.readlines()
#         print(lines)
#         # å› ä¸ºreadlinesï¼ˆï¼‰å¯ä»¥æŠŠæ¯ä¸€è¡Œå½“åšä¸€ä¸ªå…ƒç´ å‚¨å­˜èµ·æ¥ï¼Œæ‰€ä»¥for line in lineså°±ä¼šéå†æ¯ä¸€è¡Œ
#     for line in lines:
#         line = line.strip()  # å› ä¸ºreadlineså®ƒåŒ…æ‹¬æ¢è¡Œç¬¦ï¼Œæ‰€ä»¥strip()æ˜¯å°†æ¢è¡Œç¬¦ç»™å»äº†
#         # print(line)
#         components = line.split()
#         # print(components)
#         x_landmark_list = list(components[5::2])
#         # print(len(x_landmark_list))
#         # print(x_landmark_list)
#         y_landmark_list = list(components[6::2])
#         # print(y_landmark_list)
#         landmark_list = list(zip(x_landmark_list, y_landmark_list))
#         # print(x_landmark_list)
#         print(landmark_list)
#
#     return landmark_list

def get_landmark(label_txt):
    # ä¸ç”¨æƒ³ä¸€æ¬¡æ€§å°†ä¸¤ç§æ•°æ®ç±»å‹éƒ½ä¸€ä¸‹å­èƒ½åˆ†ç¦»å¼€æ¥ï¼Œåªè¦å°†å®ƒä»¬ç»Ÿä¸€æˆå­—ç¬¦ä¸²çš„å½¢å¼åˆ†å‰²å¼€æ¥ï¼Œç„¶åæƒ³è¦æ•°å­—æ˜¯åœ¨å°†å…¶è½¬åŒ–è¿‡æ¥å³å¯
    data = np.loadtxt(label_txt, dtype=str)
    # print(data)
    # å¯¹å¯¹è±¡åˆ‡ç‰‡ï¼Œsæ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œå¯ä»¥é€šè¿‡ç±»ä¼¼æ•°ç»„ç´¢å¼•çš„æ–¹å¼è·å–å­—ç¬¦ä¸²ä¸­çš„å­—ç¬¦ï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥ç”¨s[ağŸ…±ï¸c]çš„å½¢å¼å¯¹såœ¨aå’Œbä¹‹é—´ï¼Œ
    # ä»¥cä¸ºé—´éš”å–å€¼ï¼Œcçš„å€¼è¿˜å¯ä»¥ä¸ºè´Ÿï¼Œè´Ÿå€¼åˆ™æ„å‘³ç€åå‘å–å€¼, æ‰€ä»¥è¿™é‡Œ5::;3æ„å‘³ç€ä»5å¼€å§‹å»å€¼ä¸€ç›´å–å®Œï¼Œå…¶é—´éš”å€¼ä¸º2
    # method 1ï¼š è¿™ä¸ªå®¹æ˜“ç†è§£
    # num_data = len(data[:])
    # for i in range(num_data):
    #     x_landmark = data[i,5::2].astype("float")
    #     # print(x_landmark)
    #     y_landmark = data[i,6::2].astype("float")
    #     landmark = np.array(list(zip(x_landmark, y_landmark)))
    # method 2ï¼šè¿™ä¸ªè¿è¡Œæ›´å¥½
    # å°†å…¶å˜æ¢æˆï¼ˆ1953,1ï¼‰çš„æ•°ç»„å½¢å¼ï¼Œå†è®²å…¶åˆå¹¶ï¼Œè¿™æ ·çš„åˆ°çš„æ•°ç»„å°†ä¼šæ˜¯ä¸¤ä¸¤å¯¹åº”æ•°ç»„çš„å…ƒç´ åŒ¹é…çš„æ•°ç»„
    num_landmark_per_group = 21  # å…³é”®ç‚¹æœ‰21ä¸ª,å…¶ä¸­ä¸¤ä¸¤é…å¯¹ã€‚
    x_landmark = data[:, 5::2].astype("float").reshape(-1, 1)
    y_landmark = data[:, 6::2].astype("float").reshape(-1, 1)
    landmark = np.hstack((x_landmark, y_landmark))  # ï¼ˆ33453,2ï¼‰
    landmark = landmark.reshape(-1, num_landmark_per_group, 2)  # ï¼ˆ1593,21,2ï¼‰

    # print(landmark)

    return landmark


# gen_landmark(data1_root_file)


def expend_roi(x1, y1, x2, y2, img_w, img_h, ratio=0.25):
    width = x2 - x1 + 1  # +1æ˜¯å› ä¸ºå›¾åƒç”Ÿæˆçš„è¾¹æ¡†å®½åº¦ä¹Ÿè¦å ä¸€ä¸ªåƒç´ 
    height = y2 - y1 + 1  # è¿™ä¹Ÿå¾ˆä¸Šé¢åŒç†
    # width = torch.IntTensor(width)  # å¿…é¡»è½¬åŒ–æˆTensorræ‰èƒ½åštorchè¿ç®—æ“ä½œ
    # height = torch.IntTensor(height)
    # width = torch.abs(width)
    # height = torch.abs(height)

    # è¿™é‡Œæ˜¯éœ€è¦æ‰©å¤§åçš„å®½åº¦ï¼Œå³x1æ‰©å¤§,ç›¸å½“äºæŠŠå®½åº¦åŠ é•¿äº†0.5å€
    padding_width = np.array(width * ratio).astype("int")
    # è¿™é‡Œæ˜¯éœ€è¦æ‰©å¤§åçš„é«˜åº¦ï¼Œ å³y1æ‰©å¤§ï¼Œç›¸å½“äºæŠŠé«˜åº¦åŠ é•¿äº†0.5å€ï¼Œè¿™æ ·æ‰©å¤§åçš„é¢ç§¯å› ä¸ºæ‰©å¤§å‰çš„é¢ç§¯çš„2.25å€
    padding_height = np.array(height * ratio).astype("int")
    roi_x1 = x1 - padding_width
    roi_y1 = y1 - padding_height
    roi_x2 = x2 + padding_width
    roi_y2 = y2 + padding_height
    # è¶…è¿‡å›¾åƒçš„ç•Œé™æ—¶å³ç­‰äºä»–çš„ç•Œé™
    roi_x1 = np.where(roi_x1 < 0, 0, roi_x1)
    roi_y1 = np.where(roi_y1 < 0, 0, roi_y1)
    # roi_x2[roi_x2 > img_w] = img_w
    # roi_y2[roi_y2 > img_h] = img_h
    # 1. np.where(condition, x, y)
    # æ»¡è¶³æ¡ä»¶(condition)ï¼Œè¾“å‡ºxï¼Œä¸æ»¡è¶³è¾“å‡ºyã€‚
    roi_x2 = np.where(roi_x2>img_w, img_w, roi_x2)
    roi_y2 = np.where(roi_y2>img_h, img_h, roi_y2)
    return roi_x1, roi_y1, roi_x2, roi_y2, roi_x2 - roi_x1 + 1, roi_y2 - roi_y1 + 1


# print(expend_roi(229.0, 38.0, 289.0, 99.0, 557, 665))


def get_img_name(label_txt):
    data = np.loadtxt(label_txt, dtype=str)
    img_name = data[:, 0]
    # print(img_name)
    return img_name


# get_img_name(data1_root_file)


# def get_label_values(bboxs,landmarks):
#     data = np.column_stack((bboxs,landmarks))
#     label_values = data[:, 1:]
#     # print(label_values)
#
#     return label_values


# get_label_values(data1_root_file)


def data_split(img_name, label_values):
    '''
    æ ¼å¼ï¼š

    X_train,X_test, y_train, y_test = train_test_split(train_data,train_target,test_size=0.3, random_state=0)

    train_dataï¼šè¢«åˆ’åˆ†çš„æ ·æœ¬ç‰¹å¾é›†

    train_targetï¼šè¢«åˆ’åˆ†çš„æ ·æœ¬æ ‡ç­¾

    test_sizeï¼šå¦‚æœæ˜¯æµ®ç‚¹æ•°ï¼Œåœ¨0-1ä¹‹é—´ï¼Œè¡¨ç¤ºæ ·æœ¬å æ¯”ï¼›å¦‚æœæ˜¯æ•´æ•°çš„è¯å°±æ˜¯æ ·æœ¬çš„æ•°é‡

    random_stateï¼šæ˜¯éšæœºæ•°çš„ç§å­ã€‚
    '''
    # train_test_splitå°†çŸ©é˜µéšæœºåˆ’åˆ†ä¸ºè®­ç»ƒå­é›†å’Œæµ‹è¯•å­é›†ï¼Œå¹¶è¿”å›åˆ’åˆ†å¥½çš„è®­ç»ƒé›†æµ‹è¯•é›†æ ·æœ¬å’Œè®­ç»ƒé›†æµ‹è¯•é›†æ ‡ç­¾ã€‚
    # x_train,x_testæ˜¯å­é›†ï¼Œyä¸ºæ ‡ç­¾
    x_train, x_test, y_train, y_test = train_test_split(img_name, label_values, test_size=0.3)

    # np.column_stack()å¯ä»¥æŒ‰åˆ—è¿æ¥ä¸¤ä¸ªç»´æ•°ä¸åŒçš„æ•°ç»„
    trainset = np.column_stack((x_train, y_train))
    testset = np.column_stack((x_test, y_test))

    return trainset, testset


# trainset, testset = data_split(get_img_name(data1_root_file), get_label_values(data1_root_file))


def get_txt_file(trainset, testset, folder_dir):
    train_txt = np.savetxt(folder_dir + train_name, trainset, delimiter=" ", fmt="%s")
    test_txt = np.savetxt(folder_dir + test_name, testset, delimiter=" ", fmt="%s")

    return train_txt, test_txt


# gen_txt_file(folder_list[0])




def get_iou(bbox1, bbox2):
    bbox1 = np.array(bbox1)
    bbox2 = np.array(bbox2)

    bbox1_area = (bbox1[2] - bbox1[1]) * (bbox1[3] - bbox1[1])
    bbox2_area = (bbox2[2] - bbox2[1]) * (bbox2[3] - bbox2[1])

    left_up = np.maximum(bbox1[:2], bbox2[:2])  # è¿™ä¸ªæ˜¯å› ä¸ºåæ ‡ç³»çš„åŸç‚¹æ˜¯åŸºäºå·¦ä¸Šè§’çš„ï¼Œç”»ä¸€ä¸‹å›¾å°±æ˜ç™½äº†
    right_bottom = np.maximum(bbox2[2:], bbox2[2:])

    # è¿™é‡Œæ˜¯ä¸ºäº†æ—¢å¯ä»¥ä¿è¯æœ‰æ— äº¤æ¥æ—¶çš„é«˜å’Œå®½éƒ½æœ‰å€¼ï¼Œç›¸å½“ä¸åˆ¤æ–­äº†æœ‰æ— äº¤å‰ï¼Œæ— äº¤æ¥æ˜¯å®½å’Œé«˜éƒ½ä¸ºè´Ÿæ•°ï¼Œå³åˆ¤æ–­å…¶å€¼ä¸º0
    inter_section = np.maximum(left_up - right_bottom + 1, 0.0)
    # inter_section[0]ä¸ºå®½+è¾¹æ¡†çš„å®½åº¦1ï¼Œinter_section[1]ä¸ºé«˜+è¾¹æ¡†çš„é«˜åº¦1ã€‚å³äº¤é›†çš„é¢ç§¯
    inter_area = inter_section[0] * inter_section[1]
    union_area = bbox1_area + bbox2_area - inter_area  # å¹¶é›†çš„é¢ç§¯
    # epsæ˜¯å–éè´Ÿçš„æœ€å°å€¼ã€‚å½“è®¡ç®—çš„IOUä¸º0æˆ–ä¸ºè´Ÿï¼ˆä½†ä»ä»£ç ä¸Šæ¥çœ‹ä¸å¤ªå¯èƒ½ä¸ºè´Ÿï¼‰ï¼Œä½¿ç”¨np.finfo(np.float32).epsæ¥æ›¿æ¢ï¼Œ å½“åšå›ºå®šå¥—è·¯
    iou = np.maximum(1.0 * inter_area / union_area, np.finfo(np.float32).eps)

    return iou


def channel_norm(img):
    img = img.astype('float32')
    m_mean = np.mean(img)
    m_std = np.std(img)

    print('mean: ', m_mean)
    print('std: ', m_std)

    return (img - m_mean) / m_std

def show_landmarks(folder_dir, img_name, landmarks, expand_bbox_info):
    """Show image with landmarks"""
    imgs = os.path.join(folder_dir, img_name)
    image = Image.open(imgs)
    # img.thumbnail((480, 480))

    # ä½¿ç”¨PILè£åˆ‡å›¾ç‰‡ä½¿ç”¨PILéœ€è¦å¼•ç”¨Imageï¼Œä½¿ç”¨Imageçš„open(file)æ–¹æ³•å¯ä»¥è¿”å›æ‰“å¼€çš„å›¾ç‰‡ï¼Œä½¿ç”¨crop((x0,y0,x1,y1))æ–¹æ³•å¯ä»¥å¯¹å›¾ç‰‡åšè£åˆ‡ã€‚
    #
    # åŒºåŸŸç”±ä¸€ä¸ª4å…ƒç»„å®šä¹‰ï¼Œè¡¨ç¤ºä¸ºåæ ‡æ˜¯ (left, upper, right, lower)ï¼ŒPython Imaging Library ä½¿ç”¨å·¦ä¸Šè§’ä¸º (0, 0)çš„åæ ‡ç³»ç»Ÿ
    #
    # box(100,100,200,200)å°±è¡¨ç¤ºåœ¨åŸå§‹å›¾åƒä¸­ä»¥å·¦ä¸Šè§’ä¸ºåæ ‡åŸç‚¹ï¼Œæˆªå–ä¸€ä¸ª100*100ï¼ˆåƒç´ ä¸ºå•ä½ï¼‰çš„å›¾åƒï¼Œä¸ºæ–¹ä¾¿ç†è§£ï¼Œå¦‚ä¸‹ä¸ºç¤ºæ„å›¾boxï¼ˆb1,a1,b2,a2ï¼‰
    image = image.crop((expand_bbox_info[0, 0], expand_bbox_info[0, 1], expand_bbox_info[0, 2], expand_bbox_info[0, 3]))
    plt.imshow(image)
    plt.scatter(landmarks[0, 0::2], landmarks[0, 1::2], s=10, marker='.', c='r')
    plt.pause(10)  # pause a bit so that plots are updated
    plt.show()




def main():
    # å¾—åˆ°æ•°æ®é›†Içš„Bboxçš„æ•°æ®
    I_bbox = get_bbox(data1_root_file)
    # å¾—åˆ°æ•°æ®é›†IIçš„Bboxçš„æ•°æ®
    II_bbox = get_bbox(data2_root_file)
    # Içš„æ•°æ®é›†ä¸Šå›¾ç‰‡çš„åå­—
    I_img_names = get_img_name(data1_root_file)
    # IIçš„æ•°æ®é›†ä¸Šå›¾ç‰‡çš„åå­—
    II_img_names = get_img_name(data2_root_file)

    I_img_w_list, I_img_h_list = [], []

    II_img_w_list, II_img_h_list = [], []



    for idx in range(len(I_img_names)):
        # è¯»å–Iä¸­çš„å›¾ç‰‡
        I_img = Image.open(folder_list[0] + I_img_names[idx])

        # è·å–Iä¸­çš„å›¾ç‰‡å®½å’Œé«˜çš„å°ºå¯¸
        I_img_w, I_img_h = I_img.size
        I_img_w_list.append(I_img_w)
        I_img_h_list.append(I_img_h)

    I_img_w = np.array(I_img_w_list)
    I_img_h = np.array(I_img_h_list)

    for idx in range(len(II_img_names)):
        # è¯»å–IIä¸­çš„å›¾ç‰‡
        II_img = Image.open(folder_list[1] + II_img_names[idx])

        # è·å–IIä¸­çš„å›¾ç‰‡å®½å’Œé«˜çš„å°ºå¯¸
        II_img_w, II_img_h = II_img.size
        II_img_w_list.append(II_img_w)
        II_img_h_list.append(II_img_h)

    II_img_w = np.array(II_img_w_list)
    II_img_h = np.array(II_img_h_list)

    # è·å–æ‰©å¤§åçš„bboxçš„å·¦ä¸Šè§’åæ ‡
    I_expand_bbox_info = expend_roi(I_bbox[:, 0], I_bbox[:, 1], I_bbox[:, 2], I_bbox[:, 3], I_img_w, I_img_h)
    I_expand_bbox_info = np.array(I_expand_bbox_info).transpose()
    I_roi_x1 = I_expand_bbox_info[:, 0]
    I_roi_y1 = I_expand_bbox_info[:, 1]

    II_expand_bbox_info = expend_roi(II_bbox[:, 0], II_bbox[:, 1], II_bbox[:, 2], II_bbox[:, 3], II_img_w, II_img_h)
    II_expand_bbox_info = np.array(II_expand_bbox_info).transpose()
    II_roi_x1 = II_expand_bbox_info[:, 0]
    II_roi_y1 = II_expand_bbox_info[:, 1]

    # è·å–bboxçš„ä¸¤ä¸ªç‚¹çš„åæ ‡ä¿¡æ¯
    I_expand_bbox = I_expand_bbox_info[:, :4]
    II_expand_bbox = II_expand_bbox_info[:, :4]

    # è·å–å…³é”®ç‚¹åæ ‡
    I_landmarks = get_landmark(data1_root_file)
    II_landmarks = get_landmark(data2_root_file)

    # ä»¥å·¦ä¸Šè§’åæ ‡ä¸ºåŸç‚¹ï¼Œè·å–æ–°çš„å…³é”®ç‚¹çš„åæ ‡,æ•ˆæœæ˜¯æƒ³å°†çœŸæ­£æœ‰ç”¨çš„éƒ¨åˆ†,æ˜¯äººè„¸,ä»¥åŠäººè„¸å…³é”®ç‚¹ã€‚æ‰€ä»¥,å¸Œæœ›å¯¹äººè„¸è¿›è¡Œæˆªå–
    # å°†å…¶æ‰©å¼ ä¸ºä¸Landmarksç‚¹é›†shapeç„¶åå†ç›¸å‡ï¼Œç”¨debugæ¥è°ƒè¯•
    I_top_left_set= np.array([I_roi_x1, I_roi_y1]).transpose()
    I_top_left_set = np.repeat(I_top_left_set, 21, axis=0).reshape((-1, 21, 2))
    I_landmarks -= I_top_left_set
    I_landmarks = I_landmarks.reshape((len(I_landmarks),-1))

    II_top_left_set = np.array([II_roi_x1, II_roi_y1]).transpose()
    II_top_left_set = np.repeat(II_top_left_set, 21, axis=0).reshape((-1, 21, 2))
    II_landmarks -= II_top_left_set
    II_landmarks = II_landmarks.reshape((len(II_landmarks), -1))

    # show_landmarks(folder_list[0], I_img_names[0], I_landmarks, I_expand_bbox_info)  # æŸ¥çœ‹äººè„¸å…³é”®ç‚¹

    # Içš„æ•°æ®é›†ä¸Šå›¾ç‰‡åé¢çš„ç›¸å…³æ•°æ®ï¼Œå³æ ‡ç­¾
    I_label_values = np.concatenate((I_expand_bbox, I_landmarks), axis= 1)
    # IIçš„æ•°æ®é›†ä¸Šå›¾ç‰‡åé¢çš„ç›¸å…³æ•°æ®ï¼Œå³æ ‡ç­¾
    II_label_values = np.concatenate((II_expand_bbox, II_landmarks), axis= 1)
    # å°†Iæ•°æ®é›†åˆ’åˆ†ä¸ºtrainsetå’Œtestset
    I_trainset, I_testset = data_split(I_img_names, I_label_values)
    # å°†IIæ•°æ®é›†åˆ’åˆ†ä¸ºtrainsetå’Œtestset
    II_trainset, II_testset = data_split(II_img_names, II_label_values)

    # ç”ŸæˆIæ•°æ®é›†çš„train.txt, ç”Ÿæˆtest.txt
    get_txt_file(I_trainset, I_testset, folder_list[0])
    # ç”ŸæˆIIæ•°æ®é›†çš„train.txt, ç”Ÿæˆtest.txt
    get_txt_file(II_trainset, II_testset, folder_list[1])

    # I_roi_x1, I_roi_y1 = I_expand_bbox_info[0, 0], I_expand_bbox_info[0, 1]
    # I_roi_x2, I_roi_y2 = I_expand_bbox_info[0 ,2], I_expand_bbox_info[0, 3]


if __name__ == "__main__":
    main()
